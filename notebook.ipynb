{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install torch torchvision torchaudio\n",
    "#!python -m pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer un datasets prefait (MNIST)\n",
    "\n",
    "traning_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(traning_dataset), size=(1,)).item()\n",
    "    img, label = traning_dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(traning_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dims):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fcs = nn.ModuleList(\n",
    "            [nn.Linear(dims[i], dims[i+1]) for i in range(len(dims)-1)]\n",
    "        )\n",
    "        self.act = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        for layer in self.fcs:\n",
    "            x =layer(x)\n",
    "            x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "model = MLP([input_dim, 128, 128, output_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fcs): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       "  (act): ReLU()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        ypred = model(X)\n",
    "        loss = loss_fn(ypred, y)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{len(dataloader.dataset)}]\")\n",
    "    \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            ypred = model(X)\n",
    "            test_loss += loss_fn(ypred, y).item()\n",
    "            correct += (ypred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= len(dataloader.dataset)\n",
    "    correct /= len(dataloader.dataset)\n",
    "    print(f\"Test loss: {test_loss:>8f} | test accuracy: {correct * 100:>7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 10\n",
    "# for t in range(epochs):\n",
    "#     print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "#     train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "#     test_loop(test_dataloader, model, loss_fn)\n",
    "# print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer un datasets prefait (MNIST)\n",
    "\n",
    "traning_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1325) tensor(0.3039)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "mean, std = 0,0\n",
    "\n",
    "combined_data = ConcatDataset([traning_dataset, test_dataset])\n",
    "\n",
    "for image, label in combined_data:\n",
    "    image = image.view(28*28)\n",
    "    mean += image.mean()\n",
    "    std += image.std().sum()\n",
    "\n",
    "mean/= len(combined_data)\n",
    "std /= len(combined_data)\n",
    "\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer un datasets prefait (MNIST)\n",
    "\n",
    "traning_dataset_v2 = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.Compose([T.ToTensor(), T.Normalize((mean), (std))])\n",
    ")\n",
    "\n",
    "test_dataset_v2 = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.Compose([T.ToTensor(), T.Normalize((mean), (std))])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6252e-06) tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "mean, std = 0,0\n",
    "\n",
    "combined_data = ConcatDataset([traning_dataset_v2, test_dataset_v2])\n",
    "\n",
    "for image, label in combined_data:\n",
    "    image = image.view(28*28)\n",
    "    mean += image.mean()\n",
    "    std += image.std().sum()\n",
    "\n",
    "mean/= len(combined_data)\n",
    "std /= len(combined_data)\n",
    "\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 10\n",
    "# for t in range(epochs):\n",
    "#     print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "#     train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "#     test_loop(test_dataloader, model, loss_fn)\n",
    "# print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accélérateur: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Accélérateur: {device}\")\n",
    "\n",
    "input_dim = 28*28\n",
    "output_dim = 10 #Nombre de classe\n",
    "model = MLP([input_dim, 128, 128, output_dim]).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10 complete\n",
      "\n",
      "Epoch 2/10\n",
      "Epoch 2/10 complete\n",
      "\n",
      "Epoch 3/10\n",
      "Epoch 3/10 complete\n",
      "\n",
      "Epoch 4/10\n",
      "Epoch 4/10 complete\n",
      "\n",
      "Epoch 5/10\n",
      "Epoch 5/10 complete\n",
      "\n",
      "Epoch 6/10\n",
      "Epoch 6/10 complete\n",
      "\n",
      "Epoch 7/10\n",
      "Epoch 7/10 complete\n",
      "\n",
      "Epoch 8/10\n",
      "Epoch 8/10 complete\n",
      "\n",
      "Epoch 9/10\n",
      "Epoch 9/10 complete\n",
      "\n",
      "Epoch 10/10\n",
      "Epoch 10/10 complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/mnist_experiment_1')\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, batch_size):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    return epoch_loss / len(dataloader), correct / len(dataloader.dataset) * 100\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    return test_loss / len(dataloader), correct / len(dataloader.dataset) * 100\n",
    "\n",
    "# Training loop with added graphing\n",
    "def train_and_test(dataloader_train, dataloader_test, model, loss_fn, optimizer, epochs, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        # Train the model\n",
    "        train_loss, accuracy = train_loop(dataloader_train, model, loss_fn, optimizer, batch_size)\n",
    "        writer.add_scalars('Loss', {'train': train_loss}, epoch)\n",
    "        writer.add_scalars('Accuracy', {'train': accuracy}, epoch)\n",
    "\n",
    "        # Test the model\n",
    "        test_loss, accuracy = test_loop(dataloader_test, model, loss_fn)\n",
    "        writer.add_scalars('Loss', {'test': test_loss}, epoch)\n",
    "        writer.add_scalars('Accuracy', {'test': accuracy}, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} complete\\n\")\n",
    "\n",
    "train_and_test(train_dataloader, test_dataloader, model, loss_fn, optimizer, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*14*14, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(cnn.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10 complete\n",
      "\n",
      "Epoch 2/10\n",
      "Epoch 2/10 complete\n",
      "\n",
      "Epoch 3/10\n",
      "Epoch 3/10 complete\n",
      "\n",
      "Epoch 4/10\n",
      "Epoch 4/10 complete\n",
      "\n",
      "Epoch 5/10\n",
      "Epoch 5/10 complete\n",
      "\n",
      "Epoch 6/10\n",
      "Epoch 6/10 complete\n",
      "\n",
      "Epoch 7/10\n",
      "Epoch 7/10 complete\n",
      "\n",
      "Epoch 8/10\n",
      "Epoch 8/10 complete\n",
      "\n",
      "Epoch 9/10\n",
      "Epoch 9/10 complete\n",
      "\n",
      "Epoch 10/10\n",
      "Epoch 10/10 complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/mnist_experiment_2')\n",
    "train_and_test(train_dataloader, test_dataloader, cnn, loss_fn, optimizer, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install onnx\n",
    "#!python -m pip install onnxscript\n",
    "#!python -m pip install onnxruntime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.to(\"cpu\")\n",
    "torch_input = torch.randn(1, 1, 28, 28)\n",
    "onnx_program = torch.onnx.export(\n",
    "    cnn,\n",
    "    torch_input,\n",
    "    \"model.onnx\",\n",
    "    verbose=True,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    opset_version=11,\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\"},\n",
    "        \"output\": {0: \"batch_size\"}\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input length: 1\n",
      "Sample input: [tensor([[[[-1.3741e+00,  3.9748e-01,  5.7270e-01,  1.1509e-01, -1.4141e-01,\n",
      "            6.4125e-02,  1.1042e+00,  3.7835e-01, -1.1949e+00, -6.0085e-01,\n",
      "            5.5973e-01, -1.0878e+00, -3.3833e-01, -7.4809e-01,  1.9670e+00,\n",
      "            4.2096e-01,  5.1701e-01, -4.5877e-02, -3.6588e-01, -1.8129e-01,\n",
      "           -1.0295e-01,  1.8235e-01, -1.1372e+00,  8.0638e-01, -1.2078e+00,\n",
      "           -1.3751e+00,  1.4226e+00,  5.1749e-01],\n",
      "          [-1.8715e+00, -1.3260e+00,  7.2624e-02, -8.4867e-01, -1.2534e+00,\n",
      "            6.9968e-01, -4.5868e-01,  1.0252e+00, -5.1438e-01,  6.1551e-01,\n",
      "            4.1050e-01, -1.6398e+00,  1.0655e+00, -5.5289e-01, -5.2404e-01,\n",
      "            1.7268e-01, -9.8505e-01,  2.1879e+00, -2.9261e+00, -8.3165e-01,\n",
      "            5.9078e-01, -2.5902e-01, -8.7719e-01, -3.7393e-02,  5.3406e-01,\n",
      "           -2.4005e+00,  3.4399e-01,  7.4295e-01],\n",
      "          [-2.6156e-01, -5.1278e-01,  9.2012e-02, -1.0566e+00,  8.6395e-01,\n",
      "           -7.6069e-01, -3.0496e-01,  1.4875e+00,  4.5721e-01, -1.2253e+00,\n",
      "            1.1301e+00, -4.4351e-01, -9.6569e-01, -2.9058e-01,  1.6531e+00,\n",
      "           -5.3513e-01, -1.8172e-02, -3.9739e-01,  1.0983e+00, -6.4192e-01,\n",
      "            8.7889e-01, -5.5510e-02, -5.2999e-01,  6.2089e-01, -2.2153e+00,\n",
      "           -1.9484e+00, -3.5699e-01, -2.3397e-01],\n",
      "          [ 7.7893e-01, -1.3130e+00, -1.3051e+00, -9.0673e-01, -3.3907e-01,\n",
      "           -6.4788e-01, -9.5117e-01,  1.2607e+00, -7.2179e-01,  4.6816e-01,\n",
      "           -1.7693e+00, -5.1334e-01,  2.0340e-01, -4.7669e-01, -3.0627e-01,\n",
      "            7.4046e-02,  8.6368e-01,  1.2131e+00,  6.0834e-01, -5.0255e-01,\n",
      "           -2.6235e-01, -6.3126e-01,  1.1676e+00,  2.2671e-01, -1.9416e+00,\n",
      "            6.1718e-02, -6.4586e-01, -5.2972e-01],\n",
      "          [ 1.2428e-01, -1.5839e+00, -6.8716e-01, -4.8240e-01, -1.4724e-01,\n",
      "            3.3201e-01, -8.6308e-01, -3.7356e-01,  6.5852e-01,  3.9384e-01,\n",
      "            5.1811e-01, -8.2989e-01,  1.1737e-01, -1.2818e+00, -3.8008e-02,\n",
      "            2.7964e-01,  1.1417e+00,  2.3307e-01, -1.7258e+00, -1.1552e+00,\n",
      "           -1.6412e+00,  2.8097e-01,  1.7801e-01, -1.1696e+00, -5.2486e-01,\n",
      "            4.5993e-01, -1.8244e-01,  1.8944e+00],\n",
      "          [-8.5128e-01, -1.7349e-01,  4.1856e-01, -2.8083e-01, -1.4727e+00,\n",
      "            2.1824e+00,  2.9069e+00, -1.4086e-01, -1.1303e-01,  2.0813e-01,\n",
      "            8.3791e-01, -1.1021e+00, -2.6548e-01,  1.0322e+00,  5.0956e-01,\n",
      "            8.0729e-01, -4.5368e-01, -1.5306e-01,  6.7323e-01, -4.3773e-01,\n",
      "            1.9036e+00,  6.5300e-01,  2.7755e-01,  2.6891e-01,  2.8341e+00,\n",
      "            1.2941e+00,  2.7110e-01,  2.4573e-02],\n",
      "          [-4.5584e-01,  7.2423e-01, -3.8320e-01,  4.2047e-01,  5.9734e-01,\n",
      "           -9.1256e-01, -1.7692e-01,  1.8434e+00,  6.2259e-01, -1.8844e+00,\n",
      "            7.2690e-01, -1.7460e-01, -1.3806e-01, -2.0701e+00, -3.9487e-01,\n",
      "           -1.9132e+00, -8.9701e-01, -9.5867e-02,  1.1059e+00,  2.7482e-01,\n",
      "           -1.1215e+00, -1.9764e-01,  4.2395e-01, -4.3052e-01, -1.5927e+00,\n",
      "            6.3509e-02,  2.2212e-01,  9.0439e-01],\n",
      "          [ 8.2586e-01, -4.8047e-01, -7.2958e-01, -2.8420e-01,  4.5994e-01,\n",
      "            6.5463e-01, -5.5100e-01, -7.2153e-01,  4.6738e-01,  9.1661e-01,\n",
      "            3.2486e-01, -2.4620e-03,  9.1281e-01,  1.0370e+00,  7.3593e-01,\n",
      "            2.1126e-01, -1.3761e+00, -1.5606e+00, -7.9051e-01,  1.0717e+00,\n",
      "            7.2005e-01,  2.8426e-01, -3.5543e-01, -6.3034e-01,  7.3703e-01,\n",
      "            2.6262e-01,  1.8975e+00, -1.6921e+00],\n",
      "          [-5.9543e-01,  1.5503e-01,  3.2949e-01,  5.7805e-01, -1.7517e+00,\n",
      "           -2.5569e-01,  7.0796e-01, -2.3649e+00, -3.4462e-01,  2.4632e-01,\n",
      "            7.8503e-01,  8.7780e-01,  1.6027e+00, -1.8803e-01, -1.2596e+00,\n",
      "           -1.0114e+00, -1.3418e+00,  1.2595e+00, -3.8555e-01,  1.0890e+00,\n",
      "            6.9207e-01,  1.1356e+00, -8.4574e-01,  7.2651e-01,  1.2001e+00,\n",
      "           -7.8210e-01, -8.2751e-01, -7.2027e-01],\n",
      "          [ 6.8671e-01, -1.1793e+00, -2.7482e+00,  2.4623e-01,  6.9458e-01,\n",
      "           -8.2024e-01, -6.1620e-01, -1.0715e+00,  4.2892e-01,  3.4101e-01,\n",
      "           -8.8985e-01, -2.6718e-01, -5.5666e-01,  1.6411e+00, -2.4979e-01,\n",
      "           -1.9950e+00, -1.3906e+00,  1.0260e+00,  9.7889e-02, -1.5337e-01,\n",
      "            2.9474e-01,  6.0789e-01, -3.9125e-01,  4.9238e-01, -5.5740e-01,\n",
      "            8.2294e-01, -1.0343e+00, -6.2315e-01],\n",
      "          [ 1.3191e+00,  8.5325e-01, -5.0569e-01, -1.9684e+00,  6.4624e-01,\n",
      "            7.9208e-02, -1.4360e+00,  7.1873e-01, -5.4791e-01,  2.1647e+00,\n",
      "            3.0890e-01,  4.4892e-01,  1.5412e+00,  6.3759e-01, -5.7326e-01,\n",
      "            2.7817e-01,  1.2295e+00, -1.9631e-01,  5.2260e-01, -1.1697e-01,\n",
      "            5.2176e-01, -8.9379e-01,  1.3824e+00,  4.2691e-01,  2.6088e-01,\n",
      "            5.1211e-01, -6.8835e-01,  2.6312e-01],\n",
      "          [-6.9785e-02, -2.0205e-01,  8.9861e-02,  4.0812e-02, -1.1446e+00,\n",
      "           -1.2596e+00, -1.2530e-01, -1.7100e+00, -5.5032e-01, -1.3859e+00,\n",
      "            2.2592e-01, -1.5641e+00, -1.3568e+00, -1.4820e+00,  2.2853e-01,\n",
      "            8.3630e-01,  2.8043e-01,  5.4629e-01, -1.3436e-01, -1.2736e+00,\n",
      "           -2.8857e-01,  1.0533e+00,  8.7402e-01,  5.1738e-02,  2.3393e-01,\n",
      "           -8.5402e-01, -9.0903e-01, -7.0801e-01],\n",
      "          [-4.1419e-02,  3.7119e-01,  7.5212e-01,  1.2278e+00,  1.1979e+00,\n",
      "            1.4453e-01, -1.2016e+00,  4.8252e-01,  8.7354e-01,  2.3690e+00,\n",
      "            7.4478e-01, -4.0665e-01, -5.5529e-01, -1.2837e+00, -1.1737e-01,\n",
      "            2.9569e-01,  3.3105e-01,  1.2764e+00, -5.8059e-01,  1.0609e+00,\n",
      "            3.9278e-01,  4.9880e-01,  4.6294e-01, -2.3833e+00,  3.1525e-01,\n",
      "           -1.5685e-01, -7.6432e-01, -4.4152e-01],\n",
      "          [ 2.0627e-02, -1.9590e+00, -7.2140e-01, -3.3083e-01, -4.0284e-01,\n",
      "           -2.4824e-01,  1.0433e+00, -5.6200e-01, -4.9479e-01, -2.3216e+00,\n",
      "           -4.4468e-01, -6.8023e-01, -3.2332e-01, -3.9063e-01, -1.8111e+00,\n",
      "            9.6505e-01,  1.7807e+00, -6.0784e-01, -1.1021e-01,  4.2873e-01,\n",
      "            4.8785e-01,  8.4389e-01,  1.7826e+00,  1.3602e-01,  1.1085e+00,\n",
      "            1.9199e-01, -6.4369e-01, -6.4737e-01],\n",
      "          [-1.2290e+00, -1.7189e-01, -5.2938e-01, -7.2290e-01, -1.8697e-01,\n",
      "            3.7088e-02,  2.0315e+00,  3.5495e-01,  7.5546e-01, -1.7559e+00,\n",
      "            2.5993e+00,  1.9049e+00,  8.2307e-02,  6.6995e-01,  5.8259e-01,\n",
      "            5.0395e-01,  3.9244e-01,  3.6683e-01,  1.1912e+00,  1.0569e-01,\n",
      "            3.5322e-01, -3.4453e-01,  8.3183e-02,  2.4621e-01,  1.5962e+00,\n",
      "            3.3798e-01,  3.6309e-01, -7.2716e-01],\n",
      "          [ 7.1901e-01, -5.4295e-01, -8.1499e-01, -1.0590e+00, -1.3453e-01,\n",
      "            1.8583e-02, -1.2323e+00, -2.2377e+00, -7.8978e-01,  2.5734e-01,\n",
      "           -1.0016e+00, -9.0898e-02, -1.0389e+00, -3.0619e-01, -1.4734e-01,\n",
      "            1.4687e+00, -1.4108e+00, -5.9348e-01,  2.2131e+00,  2.0646e+00,\n",
      "           -9.6216e-01, -9.1206e-02,  1.6086e-01, -5.3614e-01, -4.1948e-01,\n",
      "           -9.6248e-01,  1.3592e+00,  1.2780e+00],\n",
      "          [-2.0872e-01,  6.4658e-01, -1.3695e+00, -1.1436e-01,  2.1243e-01,\n",
      "            6.7209e-01, -1.5169e+00,  3.9761e-01, -9.7658e-01,  5.6997e-01,\n",
      "           -2.2802e+00,  8.2510e-01,  2.3548e+00, -4.3038e-01,  2.6224e-01,\n",
      "            1.1429e+00, -9.4822e-01, -1.2654e-01,  1.7282e-01,  6.8317e-01,\n",
      "            1.7332e+00,  3.0454e-01,  4.5857e-01, -1.1707e+00, -6.6186e-01,\n",
      "            1.2916e+00,  5.6206e-01,  1.1423e+00],\n",
      "          [-7.0692e-02, -1.1275e+00,  9.6149e-01,  1.1011e+00, -2.3849e-01,\n",
      "           -5.6275e-01, -1.7619e+00,  1.9533e+00, -5.1980e-02, -1.2220e-02,\n",
      "           -4.9140e-01, -1.5834e+00,  1.0059e+00, -3.6942e-01,  1.5225e-01,\n",
      "           -2.0050e+00, -2.5472e-01, -8.1047e-01, -8.0477e-01,  1.5370e+00,\n",
      "           -4.4460e-01,  1.3518e+00, -8.9121e-01,  1.0365e+00,  2.4853e-01,\n",
      "           -1.6006e+00, -7.8903e-01, -4.6263e-01],\n",
      "          [-1.1244e+00, -3.7576e-01,  5.8616e-01,  1.1314e+00, -5.3142e-01,\n",
      "            1.0769e+00, -1.2345e+00, -1.3555e+00, -4.3969e-01, -6.6757e-01,\n",
      "           -1.7643e-01, -1.2224e+00,  6.0132e-01, -1.8325e+00,  6.7223e-01,\n",
      "           -7.5337e-01, -1.1789e+00, -1.2680e+00, -1.1207e+00, -1.6855e+00,\n",
      "           -1.1976e+00,  1.2075e+00, -1.6776e-01,  1.2256e+00,  8.9383e-02,\n",
      "            2.6085e-01, -1.4263e-01,  3.1530e-01],\n",
      "          [-5.8610e-01, -6.3765e-01, -1.7003e+00,  6.0278e-01,  7.3665e-01,\n",
      "            5.1111e-01,  7.5742e-02,  9.7084e-01,  9.1628e-01,  6.6205e-01,\n",
      "            3.5622e-01, -5.8174e-01,  1.1491e-01, -1.1006e+00,  7.9680e-01,\n",
      "           -1.6498e+00, -9.0117e-02,  1.7436e+00, -4.6997e-01,  8.1673e-01,\n",
      "            2.4659e+00, -5.7560e-01, -5.3731e-01,  2.2534e-01,  6.2019e-01,\n",
      "           -6.8339e-01, -2.3578e-01,  1.7827e+00],\n",
      "          [-2.7555e-01,  5.1459e-01, -5.2178e-01, -5.3865e-02,  1.2801e+00,\n",
      "           -1.4306e-02, -1.3850e+00, -8.1728e-01,  1.2228e-01, -2.8066e-01,\n",
      "           -3.8381e-01, -2.4871e+00,  2.1581e-01, -6.8798e-01, -8.7483e-01,\n",
      "           -4.4999e-01,  2.6567e-01, -4.2881e-01, -1.4223e+00,  4.8649e-02,\n",
      "            2.4789e-01, -5.8378e-01, -2.4969e-01,  8.9693e-01,  1.7346e+00,\n",
      "            1.0373e+00, -1.6142e-01,  1.7826e-01],\n",
      "          [ 6.5202e-01,  2.0802e+00, -3.6739e-01,  8.7609e-01, -1.2699e+00,\n",
      "           -5.4729e-01, -1.3804e+00, -1.0296e+00,  7.8709e-01,  4.7705e-01,\n",
      "            8.6574e-01, -5.7250e-01,  3.3103e-01, -2.6533e-01, -7.7542e-02,\n",
      "           -1.2728e+00,  9.1793e-01, -5.8024e-01, -5.9064e-01, -1.8885e+00,\n",
      "            1.9728e-01, -2.8172e-01,  1.2585e+00, -1.3799e+00, -3.4528e-01,\n",
      "            1.9124e-01,  7.8395e-01, -8.2910e-01],\n",
      "          [-1.5168e+00, -8.2535e-01,  3.8927e-01,  6.1086e-01, -6.0219e-01,\n",
      "           -9.1976e-02,  7.7227e-01, -1.9320e-01,  1.3429e+00, -1.5723e+00,\n",
      "            5.2448e-01,  2.3173e-01,  6.9145e-01,  6.3706e-01, -9.9200e-01,\n",
      "           -5.8383e-01, -7.2334e-01, -2.3714e-01, -7.8968e-01,  1.2026e-01,\n",
      "            1.5177e+00, -1.5438e+00, -2.1805e+00, -4.9360e-01, -4.4411e-01,\n",
      "            3.0225e-01,  1.0629e+00, -6.6345e-01],\n",
      "          [ 1.0734e+00, -1.7568e+00,  1.1927e+00,  6.5026e-01,  1.8518e+00,\n",
      "           -2.3443e+00, -2.6749e-01, -4.9976e-01,  5.4637e-01, -4.3475e-01,\n",
      "            2.4857e+00,  7.3837e-01,  9.3274e-01,  7.6763e-01,  1.0040e-01,\n",
      "           -8.8898e-01, -2.6670e-01, -3.5527e-01,  6.9533e-01, -9.3969e-01,\n",
      "           -1.9365e+00,  7.4997e-01, -1.7718e+00, -2.1727e+00, -5.6331e-01,\n",
      "           -5.2777e-02,  4.7286e-01,  8.6392e-01],\n",
      "          [-1.9329e+00,  2.2782e-01, -3.9566e-01,  6.5776e-01,  5.7743e-01,\n",
      "           -9.7321e-02, -2.3964e-01,  6.8239e-01,  7.6507e-01, -5.0423e-01,\n",
      "           -5.9796e-02,  2.2156e+00, -3.5733e-01, -7.1004e-02, -9.7482e-01,\n",
      "            3.0944e-01, -2.1732e-01, -8.9318e-02, -2.3583e-01, -9.3283e-01,\n",
      "           -8.6556e-01,  8.8595e-01,  3.2878e-01,  1.8481e-01, -6.4464e-01,\n",
      "            7.6807e-01, -5.9601e-01, -3.7910e-01],\n",
      "          [ 1.3479e+00, -4.2982e-01, -4.3986e-01, -6.5180e-01,  6.3700e-01,\n",
      "           -2.2924e+00, -1.6169e+00,  3.1394e-01, -1.2153e+00,  6.6766e-01,\n",
      "            6.4730e-01, -1.5289e-02, -1.1477e+00, -1.5847e-01, -1.1546e+00,\n",
      "            7.1303e-01,  7.6019e-02,  2.3492e-01,  1.4341e+00, -5.4667e-01,\n",
      "            3.7110e-01, -7.0852e-01, -7.1506e-01,  1.3214e-01,  6.9913e-01,\n",
      "           -9.7445e-02, -1.6935e-02, -9.0068e-01],\n",
      "          [-9.0812e-01,  5.0052e-01,  1.1254e+00,  1.1337e+00,  1.5376e+00,\n",
      "            1.2614e+00, -2.2535e+00, -3.8393e-01,  4.7961e-02,  6.5208e-01,\n",
      "            1.7253e-01,  5.1873e-01, -4.3324e-01,  1.7644e+00,  8.7917e-01,\n",
      "            1.6991e-03, -5.1091e-01, -7.9731e-01, -1.2257e+00, -1.2830e+00,\n",
      "           -1.0913e+00, -1.3841e-01,  2.5622e-01,  1.0911e+00,  4.0049e-01,\n",
      "           -1.3375e+00,  1.8594e-01, -1.9883e+00],\n",
      "          [-9.9666e-01,  6.1306e-02,  1.5130e-01, -2.9731e-02,  2.4890e-02,\n",
      "           -2.5897e+00, -7.4473e-01,  4.0193e-02,  8.8228e-01, -7.8579e-01,\n",
      "            6.5172e-01, -1.0719e+00,  4.4071e-01,  8.2639e-01, -2.4842e-01,\n",
      "            2.6176e+00, -8.9702e-01, -8.4586e-01, -7.8293e-01,  1.1011e+00,\n",
      "            4.5706e-01, -3.7300e-01, -1.7419e+00, -1.1538e-01,  9.7799e-01,\n",
      "           -2.1266e-01, -3.3850e+00,  1.9754e+00]]]])]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "onnx_input = [torch_input]\n",
    "print(f\"Input length: {len(onnx_input)}\")\n",
    "print(f\"Sample input: {onnx_input}\")\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"./model.onnx\", providers=['CPUExecutionProvider'])\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "onnxruntime_input = {k.name: to_numpy(v) for k, v in zip(ort_session.get_inputs(), onnx_input)}\n",
    "\n",
    "# onnxruntime returns a list of outputs\n",
    "onnxruntime_outputs = ort_session.run(None, onnxruntime_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch and ONNX Runtime output matched!\n",
      "Output length: 1\n",
      "Sample output: [[ -5.839282   -3.6005633  10.286593   -2.2662294  -3.691333  -10.707891\n",
      "   -5.088867    1.1821382   6.063161   -9.791163 ]]\n"
     ]
    }
   ],
   "source": [
    "torch_outputs = cnn(torch_input)\n",
    "\n",
    "assert len(torch_outputs) == len(onnxruntime_outputs)\n",
    "for torch_output, onnxruntime_output in zip(torch_outputs, onnxruntime_outputs):\n",
    "    torch.testing.assert_close(torch_output, torch.tensor(onnxruntime_output))\n",
    "\n",
    "print(\"PyTorch and ONNX Runtime output matched!\")\n",
    "print(f\"Output length: {len(onnxruntime_outputs)}\")\n",
    "print(f\"Sample output: {onnxruntime_outputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
